{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 编写爬虫程序，对于用户输入的任意关键词，获取360搜索网站（https://www.so.com/）对该关键词的搜索结果HTML代码，并打印显示此时的url地址。\n",
    "- 通过浏览器在360搜索网站上任意搜索一个关键词KeyWord，然后观察其url地址。编写对于爬虫来说，只要替换其中的KeyWord，就可以向搜索引擎提交关键词。\n",
    "- 根据用户输入的关键词，设置好当前url，使用requests库的get()方法实现对指定url的请求，并观察response响应对象的url链接和text内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.so.com/s?ie=utf-8&fr=none&src=360sou_newhome&q='\n",
    "keyword = 'python编程'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url+keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.so.com/s?ie=utf-8&fr=none&src=360sou_newhome&q=python%E7%BC%96%E7%A8%8B\n"
     ]
    }
   ],
   "source": [
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.encoding = 'utf-8'\n",
    "with open('./result/question1.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 编写爬虫程序，爬取诗词名句网页http://www.shicimingju.com/book/sanguoyanyi.html中《三国演义》共计一百二十回的内容，并整合存储到本地文本文件中。\n",
    "- 每一回的内容分布在不同的页面，自动构建每一页的url地址。\n",
    "- 观察每一页对应的源代码，提取每一回的内容。\n",
    "- 遍历所有页，将所有回的内容整合在一起，保存到本地文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对首页的页面数据进行爬取\n",
    "#UA伪装\n",
    "headers={\n",
    "   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.25 Safari/537.36 Core/1.70.3741.400 QQBrowser/10.5.3863.400'\n",
    "}\n",
    "#指定URL\n",
    "url = 'http://www.shicimingju.com/book/sanguoyanyi.html'\n",
    "#发起请求\n",
    "page_text = requests.get(url=url,headers=headers)\n",
    "page_text.encoding = 'utf-8'\n",
    "page_text = page_text.text\n",
    "#在首页中解析出章节的标题和详情页的url\n",
    "#step1 实例化BeautifulSoup对象，需要将页面源码加载到该对象中\n",
    "\n",
    "soup = BeautifulSoup(page_text,'lxml')\n",
    "#解析章节标题和详情页url\n",
    "li_list = soup.select('.book-mulu > ul > li')\n",
    "# fp = open('./sanguo.txt','w',encoding='utf-8')\n",
    "for li in li_list:\n",
    "    title = li.a.string\n",
    "    filename = ''.join(title.split(' '))\n",
    "    detail_url ='http://www.shicimingju.com'+li.a['href']#超链接不是完整URL，需要点击超链接查看完整URL\n",
    "    #对详情页发起请求，解析出章节内容\n",
    "    detail_page_text = requests.get(url=detail_url,headers=headers)\n",
    "    detail_page_text.encoding = 'utf-8'\n",
    "    detail_page_text = detail_page_text.text\n",
    "    #解析出详情页中相关的章节内容\n",
    "    detail_soup = BeautifulSoup(detail_page_text,'lxml')\n",
    "    div_tag = detail_soup.find('div',class_='chapter_content')\n",
    "    #解析到了章节的内容\n",
    "    content = div_tag.text\n",
    "   #  fp.write(title+':'+content+'\\n')\n",
    "    with open('./result/三国演义/'+filename+'.txt', 'w', encoding='utf-8') as f:\n",
    "       f.write('\\n'.join(content.split('\\u3000\\u3000')))\n",
    "    print(title, \"爬取成功!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "befa846729df2e6a6dfb9ca3de3863388daaf89f0c00a3d80fa42e2081a3a994"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('AS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
